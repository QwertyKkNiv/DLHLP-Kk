algorithm_config:
  name: tacotron2
  type: tacotron2
ckpt_dir: output/RAW_TEST_LJ/ckpt
data_configs:
- data_dir: preprocessed_data/LJSpeech-1.1
  lang_id: en
  name: LJSpeech-1.1
  subsets:
    test: data_config/LJSpeech-1.1/test.txt
    train: data_config/LJSpeech-1.1/train.txt
    val: data_config/LJSpeech-1.1/val.txt
  symbol_id: en
  text_cleaners:
  - english_cleaners
log_dir: output/RAW_TEST_LJ/log
model_config:
  max_seq_len: 1000
  multi_speaker: false
  tacotron2:
    attention_dim: 128
    attention_location_kernel_size: 31
    attention_location_n_filters: 32
    attention_rnn_dim: 1024
    decoder_rnn_dim: 1024
    encoder_embedding_dim: 512
    encoder_kernel_size: 5
    encoder_n_convolutions: 3
    gate_threshold: 0.5
    mask_padding: true
    max_decoder_ratio: 10
    n_frames_per_step: 3
    p_attention_dropout: 0.1
    p_decoder_dropout: 0.1
    postnet_embedding_dim: 512
    postnet_kernel_size: 5
    postnet_n_convolutions: 5
    prenet_dim: 256
    symbols_embedding_dim: 512
  vocoder:
    model: HifiGAN
result_dir: output/RAW_TEST_LJ/result
train_config:
  optimizer:
    anneal_rate: 0.3
    anneal_steps:
    - 30000
    - 50000
    - 70000
    batch_size: 32
    betas:
    - 0.9
    - 0.999
    eps: 1.0e-09
    grad_acc_step: 1
    grad_clip_thresh: 1.0
    lr: 0.001
    warm_up_step: 4000
    weight_decay: 1.0e-06
  path:
    ckpt_path: output/RAW_TEST_LJ/ckpt
    log_path: output/RAW_TEST_LJ/log
    result_path: output/RAW_TEST_LJ/result
  step:
    log_step: 100
    save_step: 10000
    synth_step: 1000
    total_step: 50000
    val_step: 2500
